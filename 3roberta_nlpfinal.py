# -*- coding: utf-8 -*-
"""3roberta_NLPFinal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N3qY3laujZORsY5XIliqLq_gtnAQ9foA

### Script 3, Ankita Nambiar
### Sentiment Analysis: RoBERTa
"""

!pip install -q transformers

# Using pipeline class to make predictions from models available in the Hub in an easy way 
from transformers import pipeline
sentiment_pipeline = pipeline("sentiment-analysis")
data = ["I love you", "I hate you"]
sentiment_pipeline(data)

from transformers import pipeline, AutoTokenizer

# Using a specific model for sentiment analysis
specific_model = pipeline(model="cardiffnlp/twitter-roberta-base-sentiment")
specific_model(data)

!pip install pandarallel
!pip install progress

from pandarallel import pandarallel
import multiprocessing
from progress.bar import Bar # or from progressbar import ProgressBar

num_processors = multiprocessing.cpu_count()
print(f'Available CPUs: {num_processors}')

pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False, progress_bar=Bar()) # or ProgressBar()

text = ['they are banned', 'you are wrong', 'You are the best', 'I have no thoughts about you.']

import pandas as pd
pd.DataFrame(specific_model(text))

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')
df = pd.read_parquet('/content/drive/MyDrive/BERT_topic_df.parquet')
df.head()

text_list = df['important_words'].to_list()

len(text_list[2])

max_words = 1843 
truncated_texts = [text[:max_words] for text in text_list] 

result = specific_model(truncated_texts)
df_result = pd.DataFrame(result)

df_result

df_result['label'].value_counts()

df_result['sentiment'] = df_result['label']

sentiment_list = df_result['sentiment'].tolist()
#sentiment_list

df_result.info()

df['sentiment'] = sentiment_list

df.head()

df[df['sentiment'] == 'LABEL_1']



